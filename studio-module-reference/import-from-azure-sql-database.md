---
title: "ML Studio (classic): Import from Azure SQL Database - Azure"
description: Learn how to use the Import Data module to get data from an Azure SQL Database or Azure SQL Data Warehouse.  
ms.date: 05/06/2019
ms.service: "machine-learning"
ms.subservice: "studio-classic"
ms.topic: "reference"

author: likebupt
ms.author: amlstudiodocs

---
# Import from Azure SQL Database

This article describes how to use the [Import Data](import-data.md) module in Machine Learning Studio (classic), to get data from an Azure SQL Database or Azure SQL Data Warehouse.  

[!INCLUDE [studio-ui-applies-label](../includes/studio-ui-applies-label.md)]

To import data from a database, you must specify both the server name and database name, and a SQL statement that defines the table, view, or query.  

In general, storing data in Azure databases is more expensive than using tables or blobs in Azure. There may also be limits on the amount of data that you can store in a database, depending on your subscription type. However, there are no transaction fees against SQL Azure Database, so that option is ideal for fast access to smaller amounts of frequently used information, such as data lookup tables or data dictionaries.

Storing data in an Azure database is also preferred if you need to be able to filter data before reading it, or if you want to save predictions or metrics back to the database for reporting.

## How to import data from Azure SQL Database or SQL Data Warehouse

### Use the Data Import Wizard

The module features a new wizard to help you choose a storage option, select from among existing subscriptions and accounts, and quickly configure all options.

1. Add the **Import Data** module to your experiment. You can find the module in Studio (classic), in the **Data Input and Output** category.

2. Click **Launch Import Data Wizard** and follow the prompts.

3. When configuration is complete, to actually copy the data into your experiment, right-click the module, and select **Run Selected**. 

If you need to edit an existing data connection, the wizard loads all previous configuration details so that you don't have to start again from scratch

### Manually set properties in the Import Data module

The following steps describe how to manually configure the import source.

1. Add the [Import Data](import-data.md) module to your experiment. You can find this module in Studio (classic), in the [Data Input and Output](data-input-and-output.md) category.

2. For **Data source**, select **Azure SQL Database**.

3. Set the following options specific to Azure SQL Database or Azure SQL Data Warehouse.

    **Database server name**: Type the server name that is generated by Azure. Typically it has the form `<generated_identifier>.database.windows.net`.

    **Database name**: Type the name of an existing database on the server you just specified.

    **Server user account name**: Type the user name of an account that has access permissions for the database.

    **Server user account password**: Provide the password for the specified user account.

    **Database query**: Type or paste a SQL statement that describes the data you want to read. Always validate the SQL statement and verify the query results beforehand, using a tool such as Visual Studio Server Explorer or SQL Server Data Tools.
    
    > [!NOTE]
    >  **Import Data** module only supports inputting Database name, user account name and password as credentials.     

4. If the dataset that you read into Machine Learning is not expected to change between runs of the experiment, select the **Use cached results** option.

    When this is selected, if there are no other changes to module parameters, the experiment loads the data the first time the module is run, and thereafter uses a cached version of the dataset.

    If you want to re-load the dataset on each iteration of the experiment, deselect this option. The dataset is reloaded from the source each time any parameters are changed in [Import Data](import-data.md).

5. Run the experiment.

    As [Import Data](import-data.md) loads the data into Studio (classic), some implicit type conversion might also be performed, depending on the data types used in the source database.

### Results

When import is complete, click the output dataset and select **Visualize** to see if the data was imported successfully.

Optionally, you can change the dataset and its metadata using the tools in Studio (classic):

- Use [Edit Metadata](edit-metadata.md) to change column names, convert a column to a different data type, or to indicate which columns are labels or features.

- Use [Select Columns in Dataset](select-columns-in-dataset.md) to select a subset of columns.

- Use [Partition and Sample](partition-and-sample.md) to separate the dataset by criteria, or get the top n rows.

## Examples

For an example of how to use data from Azure databases in machine learning, see these articles and experiments:

- [Retail Forecasting Step 1 of 6 - data preprocessing](https://gallery.azure.ai/Experiment/Retail-Forecasting-Step-1-of-6-data-preprocessing-5): The Retail forecasting template illustrates a typical scenario that uses data stored in Azure SQLDB for analysis. 

    It also demonstrates some useful techniques, such as using Azure SQLDB to passing datasets between experiments in different accounts, saving and combining forecasts, and how to create an Azure SQLDB for machine learning.

- [Use Machine Learning with SQL Data Warehouse](https://azure.microsoft.com/documentation/articles/sql-data-warehouse-integrate-azure-machine-learning/): This article demonstrates how to create a regression model to predict prices using Azure SQL Data Warehouse.

- [How to use Azure ML with Azure SQL Data Warehouse](https://blogs.technet.microsoft.com/machinelearning/2016/03/08/how-to-use-azure-ml-with-azure-sql-data-warehouse/): This article builds a clustering model on AdventureWorks, using [Import Data](import-data.md) and [Export Data](export-data.md) with Azure SQL Data Warehouse.

## Technical notes

This section contains implementation details, tips, and answers to frequently asked questions.

### Common questions

#### Can I filter data as it is being read from the source?

The [Import Data](import-data.md) module does not support filtering as data is being read. We recommend that you create a view or define a query that generates only the rows you need.

> [!NOTE]
> If you find that you have loaded more data than you need, you can overwrite the cached dataset by reading a new dataset, and saving it with the same name as the older, larger data.

#### Why do I get the error, “Type Decimal is not supported”?

When reading data from a SQL database, you might encounter an error message reporting an unsupported data type.

If the data you get from the SQL database includes data types that are not supported in Machine Learning, you should cast or convert the decimals to a supported data before reading the data. [Import Data](import-data.md) cannot automatically perform any conversions that would result in a loss of precision.

For more information about supported data types, see [Module Data Types](machine-learning-module-data-types.md).

#### What happens if the database is in a different geographical region. Can  Import Data still access the database? Where is the data stored?

If the database is in a different region from the machine learning account, data access might be slower. Further, you are charged for data ingress and egress on the subscription if the compute node is in a different region than the storage account.

Data that you read into your workspace for an experiment is saved in the storage account associated with the experiment.

#### Why are some characters not displayed correctly?

Machine Learning supports the UTF-8 encoding. If string columns in your database use a different encoding, the characters might not be imported correctly.

One option is to export the data to a CSV  file in Azure storage, and use the option **CSV with encoding** to specify parameters for custom delimiters, the code page, and so forth.  

## Module parameters

|Name|Range|Type|Default|Description|  
|----------|-----------|----------|-------------|-----------------|  
|Data source|List|Data Source Or Sink|Azure Blob Storage|Data source can be HTTP, FTP, anonymous HTTPS or FTPS, a file in Azure BLOB storage, an Azure table, an Azure SQL Database, an on-premises SQL Server database, a Hive table, or an OData endpoint.|  
|HDFS server URI|any|String|none|HDFS rest endpoint|  
|Database server name|any|String|none|Azure storage account name|  
|Database name|any|SecureString|none|Azure storage key|  
|Server user account name|any|String|none|Azure container name|  
|Server user account name|List (subset)|Url Contents|OData|Data format type|  
|Database query|any|String|none|Data format type|  
|Use cached results|TRUE/FALSE|Boolean|FALSE|description|  

## Outputs

|Name|Type|Description|  
|----------|----------|-----------------|  
|Results dataset|[Data Table](data-table.md)|Dataset with downloaded data|  

## Exceptions

|Exception|Description|  
|---------------|-----------------|  
|[Error 0027](errors/error-0027.md)|An exception occurs when two objects have to be the same size, but they are not.|  
|[Error 0003](errors/error-0003.md)|An exception occurs if one or more of inputs are null or empty.|  
|[Error 0029](errors/error-0029.md)|An exception occurs when an invalid URI is passed.|  
|[Error 0030](errors/error-0030.md)|an exception occurs in when it is not possible to download a file.|  
|[Error 0002](errors/error-0002.md)|An exception occurs if one or more parameters could not be parsed or converted from the specified type to the type required by the target method.|  
|[Error 0009](errors/error-0009.md)|An exception occurs if the Azure storage account name or the container name is specified incorrectly.|  
|[Error 0048](errors/error-0048.md)|An exception occurs when it is not possible to open a file.|  
|[Error 0015](errors/error-0015.md)|An exception occurs if the database connection has failed.|  
|[Error 0046](errors/error-0046.md)|An exception occurs when it is not possible to create a directory on specified path.|  
|[Error 0049](errors/error-0049.md)|An exception occurs when it is not possible to parse a file.|  

For a list of errors specific to Studio (classic) modules, see [Machine Learning Error codes](errors/machine-learning-module-error-codes.md).

For a list of API exceptions, see [Machine Learning REST API Error Codes](/azure/machine-learning/studio/web-service-error-codes).

## See also

 [Import Data](import-data.md)   
 [Export Data](export-data.md)   
 [Import from Web URL via HTTP](import-from-web-url-via-http.md)   
 [Import from Hive Query](import-from-hive-query.md)   
 [Import from Azure Table](import-from-azure-table.md)   
 [Import from Azure Blob Storage](import-from-azure-blob-storage.md)   
 [Import from Data Feed Providers](import-from-data-feed-providers.md)   
 [Import from On-Premises SQL Server Database](import-from-on-premises-sql-server-database.md)
